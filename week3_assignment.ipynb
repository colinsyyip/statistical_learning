{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.models import (ModelSpec as MS)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis)\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n: int):\n",
    "    \"\"\"\n",
    "    Generating function for multivariate normal for a given n\n",
    "    \"\"\"\n",
    "    p = 15\n",
    "    n1 = int(n/2)\n",
    "    n2 = int(n/2)\n",
    "    cov_1 = np.diag(np.repeat(1, p)) + 0.2\n",
    "\n",
    "    x_class_1 = np.random.multivariate_normal(size = n1,\n",
    "                                              mean = np.repeat(3, p),\n",
    "                                              cov = cov_1)\n",
    "    x_class_2 = np.random.multivariate_normal(size = n2,\n",
    "                                              mean = np.repeat(2, p),\n",
    "                                              cov = cov_1)\n",
    "    \n",
    "    x = np.concatenate([x_class_1, x_class_2])\n",
    "    y = np.repeat([1, 2], [n1, n2])\n",
    "\n",
    "    x_col_names = [\"x%s\" % x_enum for x_enum in range(1, p + 1)]\n",
    "    df = pd.DataFrame(x,\n",
    "                      columns = x_col_names)\n",
    "    df['y'] = y\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def lda_fit_score(training: pd.DataFrame,\n",
    "                  testing: pd.DataFrame,\n",
    "                  X_start_idx: int = 0,\n",
    "                  X_end_idx: int = 3,\n",
    "                  y_idx: int = -1):\n",
    "    \"\"\"\n",
    "    Fit and score an LDA model and return the accuracy of it\n",
    "    \"\"\"\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X = training.iloc[:, X_start_idx:X_end_idx],\n",
    "            y = training.iloc[:, y_idx])\n",
    "    lda_accuracy = lda.score(X = testing.iloc[:, X_start_idx:X_end_idx],\n",
    "                             y = testing.iloc[:, y_idx])\n",
    "    \n",
    "    return lda_accuracy\n",
    "\n",
    "\n",
    "def log_reg_accuracy(training: pd.DataFrame,\n",
    "                    testing: pd.DataFrame,\n",
    "                    X_start_idx: int = 0,\n",
    "                    X_end_idx: int = 3,\n",
    "                    y_label: str = 'y'):\n",
    "    \"\"\"\n",
    "    Fit and return the balanced accuracy of a logistic regression model\n",
    "    \"\"\"\n",
    "    testing_set_X = MS(testing.iloc[:, X_start_idx:X_end_idx]).fit_transform(testing)\n",
    "\n",
    "    logreg_design = MS(training.iloc[:, X_start_idx:X_end_idx])\n",
    "    logreg_X = logreg_design.fit_transform(training)\n",
    "    logreg_y = training[y_label] == 2\n",
    "    logreg_glm = sm.GLM(logreg_y,\n",
    "                        logreg_X,\n",
    "                        family = sm.families.Binomial())\n",
    "    logreg_results = logreg_glm.fit()\n",
    "    logreg_probs = logreg_results.predict(exog = testing_set_X)\n",
    "    logreg_labels = np.array([1] * len(logreg_probs))\n",
    "    logreg_labels[logreg_probs > 0.5] = 2\n",
    "    logreg_accuracy = np.mean(logreg_labels == testing[y_label])\n",
    "\n",
    "    return logreg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 1\n",
    "\n",
    "We would expect the generative classifier, LDA, to work better on small $N$, as it relies on assumptions about the prior that can still predict in absence of large $N$. However, without a large $N$, and because it relies on prior assumptions, it will have higher bias, but lower variance given that it is using an existing distribution to classify. On the other hand, once the training set is a large $N$, logistic regression would perform better as it has enough data to calculate more significant coefficients with lower errors. This in turn produces a model witih lower bias but higher variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Small Training Set</th>\n",
       "      <th>Large Training Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.737192</td>\n",
       "      <td>0.753299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log. Reg.</th>\n",
       "      <td>0.736378</td>\n",
       "      <td>0.753299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Small Training Set  Large Training Set\n",
       "LDA                  0.737192            0.753299\n",
       "Log. Reg.            0.736378            0.753299"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_set_model_lda_accuracies = []\n",
    "large_set_model_lda_accuracies = []\n",
    "small_set_model_logreg_accuracies = []\n",
    "large_set_model_logreg_accuracies = []\n",
    "\n",
    "n_iter = 1000\n",
    "\n",
    "for _ in range(0, n_iter):\n",
    "        training_set_1  = gen_data(n = 50)\n",
    "        training_set_2 = gen_data(n = 10000)\n",
    "        testing_set = gen_data(n = 10000)\n",
    "\n",
    "        small_set_lda_accuracy = lda_fit_score(training = training_set_1,\n",
    "                                               testing = testing_set)\n",
    "        small_set_model_lda_accuracies.append(small_set_lda_accuracy)\n",
    "\n",
    "        large_set_lda_accuracy = lda_fit_score(training = training_set_2,\n",
    "                                               testing = testing_set)\n",
    "        large_set_model_lda_accuracies.append(large_set_lda_accuracy)\n",
    "\n",
    "        small_logreg_accuracy = log_reg_accuracy(training = training_set_1,\n",
    "                                                 testing = testing_set)\n",
    "        small_set_model_logreg_accuracies.append(small_logreg_accuracy)\n",
    "\n",
    "        large_logreg_accuracy = log_reg_accuracy(training = training_set_2,\n",
    "                                                 testing = testing_set)\n",
    "        large_set_model_logreg_accuracies.append(large_logreg_accuracy)\n",
    "\n",
    "small_set_lda_mean_accuracy = np.mean(small_set_model_lda_accuracies)\n",
    "large_set_lda_mean_accuracy = np.mean(large_set_model_lda_accuracies)\n",
    "small_set_logreg_mean_accuracy = np.mean(small_set_model_logreg_accuracies)\n",
    "large_set_logreg_mean_accuracy = np.mean(large_set_model_logreg_accuracies)\n",
    "\n",
    "accuracy_data = [[small_set_lda_mean_accuracy, large_set_lda_mean_accuracy],\n",
    "                 [small_set_logreg_mean_accuracy, large_set_logreg_mean_accuracy]]\n",
    "\n",
    "accuracies = pd.DataFrame(data = accuracy_data,\n",
    "                          columns = ['Small Training Set', 'Large Training Set'],\n",
    "                          index = ['LDA', 'Log. Reg.'])\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the small training set ($n=50$), we expect LDA to outperform logistic regression given that it classifies based on an assumed distribution. We see that this holds true by a very small margin, with LDA classifying with a $73.6995\\%$ accuracy as opposed to logistic regression classifying with a $73.6261\\%$ accuracy.\n",
    "- Similarly, at large sized training sets ($n=10000$), with two independent Gaussian distributed random variables, LDA and logistic regression perform at nearly equivalent levels, with logistic regression's performance improving to meet LDA's (although both have improved slightly with the significantly larger training set)\n",
    "- The relatively marginal improvements in increasing $n$ and between models can be attributed to both random variables being independent and Gaussian, hence LDA's inherent normality assumption is valid and logistic regression can easily determine the decision boundary between the random variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
